{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMAOu/JbqCM2OFExn68pJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb8a27aaf1924e889cb7907a3cbb0b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d3502db5fa2499987536b2736b307eb",
              "IPY_MODEL_9f4548fd565b4a2a8daa4e0cc6df9b6e",
              "IPY_MODEL_34cf10badb204f7299dbe4367e3eee8a"
            ],
            "layout": "IPY_MODEL_a222742e344645fba2fe3748d702b3db"
          }
        },
        "9d3502db5fa2499987536b2736b307eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67cc0ed836b4449582071bb644733846",
            "placeholder": "​",
            "style": "IPY_MODEL_1b92eb7be7eb4b4a8c45d2366eafa044",
            "value": "100%"
          }
        },
        "9f4548fd565b4a2a8daa4e0cc6df9b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54f79193cc14f07aaa436e0397c7f97",
            "max": 52117635,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b42ce397dbe49a4a74a63d27843e7f0",
            "value": 52117635
          }
        },
        "34cf10badb204f7299dbe4367e3eee8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71452274cb554b5aa7d5cd32dbe8dae3",
            "placeholder": "​",
            "style": "IPY_MODEL_dae6f75372724a908b94bc6b0ef61f45",
            "value": " 49.7M/49.7M [00:08&lt;00:00, 8.36MB/s]"
          }
        },
        "a222742e344645fba2fe3748d702b3db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67cc0ed836b4449582071bb644733846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b92eb7be7eb4b4a8c45d2366eafa044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c54f79193cc14f07aaa436e0397c7f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b42ce397dbe49a4a74a63d27843e7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71452274cb554b5aa7d5cd32dbe8dae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae6f75372724a908b94bc6b0ef61f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab2bab4943d4875a2085276e0354c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd90e31feeea43aa892f8a22975e7d03",
              "IPY_MODEL_18f71a7cface4faabdbf7237456a7586",
              "IPY_MODEL_018f1e6b9f424d37b719c99e5342a956"
            ],
            "layout": "IPY_MODEL_b61e621b75cb47fa86846f71f839e492"
          }
        },
        "cd90e31feeea43aa892f8a22975e7d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bcbdd16c009465fbc1225744f013152",
            "placeholder": "​",
            "style": "IPY_MODEL_d8684a26a08d4a928ab09ffc90753790",
            "value": "100%"
          }
        },
        "18f71a7cface4faabdbf7237456a7586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e5478ea99e4aef83e06093f21b0218",
            "max": 773236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49a285c8e4954a9b8cae7ffa55f93471",
            "value": 773236
          }
        },
        "018f1e6b9f424d37b719c99e5342a956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cfd527eb39c4ba2abdbb7c4fd1fe94d",
            "placeholder": "​",
            "style": "IPY_MODEL_0c93d6f1ca634eceb7ea4544f294ea9d",
            "value": " 755k/755k [00:00&lt;00:00, 32.4MB/s]"
          }
        },
        "b61e621b75cb47fa86846f71f839e492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bcbdd16c009465fbc1225744f013152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8684a26a08d4a928ab09ffc90753790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3e5478ea99e4aef83e06093f21b0218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a285c8e4954a9b8cae7ffa55f93471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cfd527eb39c4ba2abdbb7c4fd1fe94d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c93d6f1ca634eceb7ea4544f294ea9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BakriSakr/BakriSakr/blob/main/Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cr5QmvAoisA4",
        "outputId": "d84d53b5-eac6-4e37-d01c-4ce2a0a00363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.32-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m772.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m513.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2022.12.7)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.25.1)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3>=1.26.6\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (8.4.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->roboflow) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->roboflow) (23.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=38007cbf6e105bf66ccaa4017bf9a5256b6fd5a0f3e5ea7874ecf325f9207a91\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, urllib3, python-dotenv, pyparsing, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-0.10.1 roboflow-0.2.32 urllib3-1.26.14 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics<=8.0.20`, to intall it `pip install ultralytics<=8.0.20`.\n",
            "Downloading Dataset Version Zip in Capstone-1 to yolov8: 100% [911473 / 911473] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Capstone-1 in yolov8:: 100%|██████████| 78/78 [00:00<00:00, 6126.05it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"xjsLeo4opXyPWIuptrnB\")\n",
        "project = rf.workspace(\"capstone-iy2tt\").project(\"capstone-bfjpi\")\n",
        "dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "\n",
        "# after using roboflow to label the images and divide the images into Train, Validation and testing sets\n",
        "# we get a snippet from the website and paste it here to import out data to google collab\n",
        "# we note that it is recommended to start by setting the runtime type to GPU just for the code to run smoother"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics -q\n",
        "# we install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiLtsUKWi_Yz",
        "outputId": "ad320b74-aeb2-4242-c9f2-fcce0fb9a2cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.9/301.9 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "# we import YOLO from ultralytics and begin to cresate our model\n",
        "# when we go to github we have the option to choose between several YOLOv8 models\n",
        "# since we want to have a high accuracy but not have a slow job we are going to select the YoloV8 Medium which sits in between the nano (YoloV8n) and the xtra large (YoloV8x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "cb8a27aaf1924e889cb7907a3cbb0b5e",
            "9d3502db5fa2499987536b2736b307eb",
            "9f4548fd565b4a2a8daa4e0cc6df9b6e",
            "34cf10badb204f7299dbe4367e3eee8a",
            "a222742e344645fba2fe3748d702b3db",
            "67cc0ed836b4449582071bb644733846",
            "1b92eb7be7eb4b4a8c45d2366eafa044",
            "c54f79193cc14f07aaa436e0397c7f97",
            "0b42ce397dbe49a4a74a63d27843e7f0",
            "71452274cb554b5aa7d5cd32dbe8dae3",
            "dae6f75372724a908b94bc6b0ef61f45"
          ]
        },
        "id": "5Bk97Hr5lZvZ",
        "outputId": "f576f146-e970-4a87-d5a0-9a58c1791d01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt to yolov8m.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/49.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb8a27aaf1924e889cb7907a3cbb0b5e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch data.yaml\n",
        "# we have defined a yaml file to hold all of our data where within it we have the correct paths to each set\n",
        "# we also added the number of number of classes to fill all required information for our model to operate"
      ],
      "metadata": {
        "id": "nUTtfd-KlztA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data= \"/content/Capstone-1/data.yaml\", epochs=5)\n",
        "# now we train our model over the data that we have inserted in the yaml file\n",
        "# this purpose is for fine tuning "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "aab2bab4943d4875a2085276e0354c54",
            "cd90e31feeea43aa892f8a22975e7d03",
            "18f71a7cface4faabdbf7237456a7586",
            "018f1e6b9f424d37b719c99e5342a956",
            "b61e621b75cb47fa86846f71f839e492",
            "7bcbdd16c009465fbc1225744f013152",
            "d8684a26a08d4a928ab09ffc90753790",
            "b3e5478ea99e4aef83e06093f21b0218",
            "49a285c8e4954a9b8cae7ffa55f93471",
            "8cfd527eb39c4ba2abdbb7c4fd1fe94d",
            "0c93d6f1ca634eceb7ea4544f294ea9d"
          ]
        },
        "id": "HTrEb_Htl7rx",
        "outputId": "947f8b52-ef21-4f9d-e460-85e23374e6cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.47 🚀 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/Capstone-1/data.yaml, epochs=5, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/755k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aab2bab4943d4875a2085276e0354c54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3779749  ultralytics.nn.modules.Detect                [7, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25860373 parameters, 25860357 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Capstone-1/train/labels... 23 images, 1 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<00:00, 1315.58it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Capstone-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Capstone-1/valid/labels... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<00:00, 1686.38it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Capstone-1/valid/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 35, len(boxes) = 215. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/5      9.59G      1.813      4.666      1.061        373        640: 100%|██████████| 2/2 [00:10<00:00,  5.44s/it]\n",
            "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n",
            "                   all          6        215     0.0123     0.0837     0.0108    0.00715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/5      9.61G      1.684       4.58     0.9951        271        640: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
            "                   all          6        215     0.0128     0.0866     0.0103    0.00625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/5      9.61G      2.195      4.947      1.078        416        640: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
            "                   all          6        215     0.0143     0.0939     0.0112     0.0059\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        4/5      9.61G      1.919      4.719      1.042        364        640: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
            "                   all          6        215     0.0125     0.0882     0.0105    0.00568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        5/5      9.61G      1.861      4.753      1.069        302        640: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
            "                   all          6        215     0.0124     0.0899     0.0097    0.00574\n",
            "\n",
            "5 epochs completed in 0.012 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.47 🚀 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25843813 parameters, 0 gradients, 78.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
            "                   all          6        215     0.0123     0.0837     0.0108    0.00723\n",
            "                    GC          6          5    0.00565        0.2    0.00351    0.00105\n",
            "                 check          6          7          0          0          0          0\n",
            "                    fm          6         59       0.05      0.203     0.0514     0.0374\n",
            "                  gate          6        101     0.0183      0.099     0.0101    0.00495\n",
            "                 globe          6         11          0          0          0          0\n",
            "                 plnao          6         32          0          0          0          0\n",
            "Speed: 0.3ms preprocess, 15.3ms inference, 0.0ms loss, 7.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "infer = YOLO(\"/content/runs/detect/train2/weights/best.pt\")\n",
        "# we are going to use our best performing fine tuned model to predict"
      ],
      "metadata": {
        "id": "LRx12FFvmxLU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer.predict(\"/content/Capstone-1/test/images\", save= True)\n",
        "# we implement the model on the testing set and we save them to look at our results and observe how the model performed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktTwMlteoP6v",
        "outputId": "8ff743ac-9fd3-45e2-e1b8-a75100d9e601"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.47 🚀 Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 218 layers, 25843813 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\n",
            "image 1/4 /content/Capstone-1/test/images/9049679-120-01-PID-Rev-01_jpg.rf.407eeddc781b49f5ccc8362b737aec94.jpg: 640x640 (no detections), 50.1ms\n",
            "image 2/4 /content/Capstone-1/test/images/9049679-120-08-PID-Rev-01_jpg.rf.007114ee3693027af31bedd5e94399a0.jpg: 640x640 (no detections), 37.8ms\n",
            "image 3/4 /content/Capstone-1/test/images/9049679-120-09-PID-Rev-01_jpg.rf.5606f665fc42f455e2595ee4ddd859a0.jpg: 640x640 (no detections), 37.7ms\n",
            "image 4/4 /content/Capstone-1/test/images/9049679-120-25-PID-Rev-01_jpg.rf.e3dd2bd1da8ebbf1a9ebf5061e87580d.jpg: 640x640 (no detections), 37.7ms\n",
            "Speed: 0.5ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6))]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from this line and beyond we will be presenting the code that changes the pdfs into jpegs and the code that cropped the pictures into what we wanted to work with\n"
      ],
      "metadata": {
        "id": "cmnDVL9xiKsJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "folder_path = ['AMA/','Lukoil UOP/']\n",
        "for path in folder_path:\n",
        "    os.mkdir(f'JPEG_{path}')\n",
        "    os.mkdir(f'CROPPED_JPEG_{path}')\n",
        "for fpath in folder_path:\n",
        "    for subdir, dirs, files in os.walk(fpath):\n",
        "        for file in files:\n",
        "            filepath = subdir + os.sep + file\n",
        "            if filepath.endswith(\".pdf\"):\n",
        "                images = convert_from_path(filepath)\n",
        "                for i, image in enumerate(images):\n",
        "                    image.save(f\"JPEG_{fpath}/{os.path.splitext(file)[0]}.jpg\", \"JPEG\")"
      ],
      "metadata": {
        "id": "cg7ySXR8c18K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our Setup, Import Libaries, Create our Imshow Function and Download our Images\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define our imshow function \n",
        "def imshow(title = \"Image\", image = None, size = 10):\n",
        "    w, h = image.shape[0], image.shape[1]\n",
        "    aspect_ratio = w/h\n",
        "    plt.figure(figsize=(size * aspect_ratio,size))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "DtQ5__lQc5UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_lukoil(picture):\n",
        "    picture = picture[16:]\n",
        "    image = cv2.imread(\"JPEG_Lukoil UOP/\"+picture, 3)\n",
        "\n",
        "    # Get our image dimensions\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Let's get the starting pixel coordiantes (top  left of cropping rectangle)\n",
        "    # using 0.25 to get the x,y position that is 1/4 down from the top left (0,0)\n",
        "    start_row, start_col = int(height * .03), int(width * .04)\n",
        "\n",
        "    # Let's get the ending pixel coordinates (bottom right)\n",
        "    end_row, end_col = int(height * .97), int(width * .82)\n",
        "\n",
        "    # Simply use indexing to crop out the rectangle we desire\n",
        "    cropped = image[start_row:end_row , start_col:end_col]\n",
        "    \n",
        "    '''\n",
        "\n",
        "    imshow(\"Original Image\", image)\n",
        "\n",
        "    # The cv2.rectangle function draws a rectangle over our image (in-place operation)\n",
        "    copy = image.copy()\n",
        "    cv2.rectangle(copy, (start_col,start_row), (end_col,end_row), (0,255,255), 10)\n",
        "\n",
        "    imshow(\"Area we are cropping\", copy)\n",
        "\n",
        "    imshow(\"Cropped Image\", cropped) \n",
        "    \n",
        "    '''\n",
        "\n",
        "    save_name = os.path.join(\"CROPPED_JPEG_LUKOIL/\", f\"{picture}\")\n",
        "    cv2.imwrite(save_name, cropped)\n",
        "    "
      ],
      "metadata": {
        "id": "DGCzmqqRdBz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_ama(picture):\n",
        "    picture = picture[9:]\n",
        "    image = cv2.imread(\"JPEG_AMA/\"+picture, 3)\n",
        "\n",
        "    # Get our image dimensions\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Let's get the starting pixel coordiantes (top  left of cropping rectangle)\n",
        "    # using 0.25 to get the x,y position that is 1/4 down from the top left (0,0)\n",
        "    start_row, start_col = int(height * .03), int(width * .027)\n",
        "\n",
        "    # Let's get the ending pixel coordinates (bottom right)\n",
        "    end_row, end_col = int(height * .97), int(width * .76)\n",
        "\n",
        "    # Simply use indexing to crop out the rectangle we desire\n",
        "    cropped = image[start_row:end_row , start_col:end_col]\n",
        "    '''\n",
        "    imshow(\"Original Image\", image)\n",
        "\n",
        "    # The cv2.rectangle function draws a rectangle over our image (in-place operation)\n",
        "    copy = image.copy()\n",
        "    cv2.rectangle(copy, (start_col,start_row), (end_col,end_row), (0,255,255), 10)\n",
        "\n",
        "    imshow(\"Area we are cropping\", copy)\n",
        "\n",
        "    imshow(\"Cropped Image\", cropped) \n",
        "    \n",
        "    # Extracting the image data &\n",
        "    # creating an numpy array out of it\n",
        "    img_arr = np.array(cropped)\n",
        "  \n",
        "    # Turning the pixel values of the 400x400 pixels to black \n",
        "    img_arr[3500 : 5000, 0 : 2000] = (255, 255, 255)\n",
        "  \n",
        "    # Creating an image out of the previously modified array\n",
        "    img = Image.fromarray(img_arr)\n",
        "    '''\n",
        "    save_name = os.path.join(\"CROPPED_JPEG_AMA/\", f\"{picture}\")\n",
        "    cv2.imwrite(save_name, cropped)\n",
        "    "
      ],
      "metadata": {
        "id": "tXGoI2M5dCfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = [\"JPEG_AMA/\",\"JPEG_Lukoil UOP\"]\n",
        "\n",
        "for folder in folder_path:\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".jpg\"):\n",
        "            file_path = os.path.join(folder, file)\n",
        "            if folder == \"JPEG_AMA/\":\n",
        "                crop_ama(str(file_path))\n",
        "            else:\n",
        "                crop_lukoil(str(file_path))"
      ],
      "metadata": {
        "id": "hQrfoM6cdGmI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}